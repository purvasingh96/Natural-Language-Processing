# Natural-Language-Processing 

## Tokenizing:
Tokenizing can be considered as a form of grouping a charecter sequence. The groups are called *tokens*. They are of 2 types - 
1. Sentence Tokenizer (sent_tokenize)
2. Word Tokenizer (word_tokenize)

## Corpora and Lexicon
*Corpora* refers to large collection of texts. E.g- medical journals, presidential speech, any English language.  
*Lexicon* refers to dictionary of words and their meanings.
